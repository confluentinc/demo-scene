---
version: '3'
services:

  kafka-connect-01:
    image: confluentinc/cp-kafka-connect:5.4.0-beta1
    container_name: kafka-connect-01
    ports:
      - 8083:8083
    environment:
      CONNECT_LOG4J_APPENDER_STDOUT_LAYOUT_CONVERSIONPATTERN: "[%d] %p %X{connector.context}%m (%c:%L)%n"
      CONNECT_CUB_KAFKA_TIMEOUT: 300
      CONNECT_BOOTSTRAP_SERVERS: "${CCLOUD_BROKER_HOST}:9092"
      CONNECT_REST_ADVERTISED_HOST_NAME: 'kafka-connect-01'
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: kafka-connect-group-01-v04
      CONNECT_CONFIG_STORAGE_TOPIC: _kafka-connect-group-01-v04-configs
      CONNECT_OFFSET_STORAGE_TOPIC: _kafka-connect-group-01-v04-offsets
      CONNECT_STATUS_STORAGE_TOPIC: _kafka-connect-group-01-v04-status
      CONNECT_KEY_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: "https://${CCLOUD_SCHEMA_REGISTRY_HOST}"
      CONNECT_KEY_CONVERTER_BASIC_AUTH_CREDENTIALS_SOURCE: "USER_INFO"
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO: "${CCLOUD_SCHEMA_REGISTRY_API_KEY}:${CCLOUD_SCHEMA_REGISTRY_API_SECRET}"
      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: "https://${CCLOUD_SCHEMA_REGISTRY_HOST}"
      CONNECT_VALUE_CONVERTER_BASIC_AUTH_CREDENTIALS_SOURCE: "USER_INFO"
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO: "${CCLOUD_SCHEMA_REGISTRY_API_KEY}:${CCLOUD_SCHEMA_REGISTRY_API_SECRET}"
      CONNECT_INTERNAL_KEY_CONVERTER: 'org.apache.kafka.connect.json.JsonConverter'
      CONNECT_INTERNAL_VALUE_CONVERTER: 'org.apache.kafka.connect.json.JsonConverter'
      CONNECT_LOG4J_ROOT_LOGLEVEL: 'INFO'
      CONNECT_LOG4J_LOGGERS: 'org.apache.kafka.connect.runtime.rest=WARN,org.reflections=ERROR'
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: '3'
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: '3'
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: '3'
      CONNECT_PLUGIN_PATH: '/usr/share/java,/usr/share/confluent-hub-components/'
      # Confluent Cloud config
      CONNECT_REQUEST_TIMEOUT_MS: "20000"
      CONNECT_RETRY_BACKOFF_MS: "500"
      CONNECT_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM: "https"
      CONNECT_SASL_MECHANISM: "PLAIN"
      CONNECT_SECURITY_PROTOCOL: "SASL_SSL"
      CONNECT_SASL_JAAS_CONFIG: "org.apache.kafka.common.security.plain.PlainLoginModule required username=\"${CCLOUD_API_KEY}\" password=\"${CCLOUD_API_SECRET}\";"
      #
      CONNECT_CONSUMER_SECURITY_PROTOCOL: "SASL_SSL"
      CONNECT_CONSUMER_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM: "https"
      CONNECT_CONSUMER_SASL_MECHANISM: "PLAIN"
      CONNECT_CONSUMER_SASL_JAAS_CONFIG: "org.apache.kafka.common.security.plain.PlainLoginModule required username=\"${CCLOUD_API_KEY}\" password=\"${CCLOUD_API_SECRET}\";"
      CONNECT_CONSUMER_REQUEST_TIMEOUT_MS: "20000"
      CONNECT_CONSUMER_RETRY_BACKOFF_MS: "500"
      #
      CONNECT_PRODUCER_SECURITY_PROTOCOL: "SASL_SSL"
      CONNECT_PRODUCER_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM: "https"
      CONNECT_PRODUCER_SASL_MECHANISM: "PLAIN"
      CONNECT_PRODUCER_SASL_JAAS_CONFIG: "org.apache.kafka.common.security.plain.PlainLoginModule required username=\"${CCLOUD_API_KEY}\" password=\"${CCLOUD_API_SECRET}\";"
      CONNECT_PRODUCER_REQUEST_TIMEOUT_MS: "20000"
      CONNECT_PRODUCER_RETRY_BACKOFF_MS: "500"
      # External secrets config
      # See https://docs.confluent.io/current/connect/security.html#externalizing-secrets
      CONNECT_CONFIG_PROVIDERS: 'file'
      CONNECT_CONFIG_PROVIDERS_FILE_CLASS: 'org.apache.kafka.common.config.provider.FileConfigProvider'
    command: 
      - bash 
      - -c 
      - |
        echo "Installing connector plugins"
        confluent-hub install --no-prompt debezium/debezium-connector-mysql:0.10.0
        confluent-hub install --no-prompt debezium/debezium-connector-sqlserver:0.10.0
        confluent-hub install --no-prompt snowflakeinc/snowflake-kafka-connector:0.5.5
        #
        echo "Launching Kafka Connect worker"
        /etc/confluent/docker/run & 
        #
        echo "Waiting for Kafka Connect to start listening on localhost:8083 ⏳"
        while : ; do
            curl_status=$$(curl -s -o /dev/null -w %{http_code} http://localhost:8083/connectors)
            echo -e $$(date) " Kafka Connect listener HTTP state: " $$curl_status " (waiting for 200)"
            if [ $$curl_status -eq 200 ] ; then
            break
            fi
            sleep 5 
        done
        #
        echo -e "\n--\n+> Creating Kafka Connect SQL Server source"
        #
        curl -i -X PUT -H  "Content-Type:application/json" \
            http://localhost:8083/connectors/source-debezium-mssql-01/config \
            -d '{
                    "connector.class": "io.debezium.connector.sqlserver.SqlServerConnector", 
                    "database.hostname": "mssql",
                    "database.port": "1433",
                    "database.user": "sa",
                    "database.password": "Admin123",
                    "database.dbname": "demo",
                    "database.server.name": "mssql",
                    "table.whitelist":"dbo.orders",
                    "database.history.kafka.bootstrap.servers": "$${file:/data/credentials.properties:CCLOUD_BROKER_HOST}:9092",
                    "database.history.kafka.topic": "dbz_dbhistory.mssql.asgard-04",
                    "database.history.consumer.security.protocol": "SASL_SSL",
                    "database.history.consumer.ssl.endpoint.identification.algorithm": "https",
                    "database.history.consumer.sasl.mechanism": "PLAIN",
                    "database.history.consumer.sasl.jaas.config": "org.apache.kafka.common.security.plain.PlainLoginModule required username=\"$${file:/data/credentials.properties:CCLOUD_API_KEY}\" password=\"$${file:/data/credentials.properties:CCLOUD_API_SECRET}\";",
                    "database.history.producer.security.protocol": "SASL_SSL",
                    "database.history.producer.ssl.endpoint.identification.algorithm": "https",
                    "database.history.producer.sasl.mechanism": "PLAIN",
                    "database.history.producer.sasl.jaas.config": "org.apache.kafka.common.security.plain.PlainLoginModule required username=\"$${file:/data/credentials.properties:CCLOUD_API_KEY}\" password=\"$${file:/data/credentials.properties:CCLOUD_API_SECRET}\";",
                    "decimal.handling.mode":"double",
                    "transforms": "unwrap,addTopicPrefix",
                    "transforms.unwrap.type": "io.debezium.transforms.ExtractNewRecordState",
                    "transforms.addTopicPrefix.type":"org.apache.kafka.connect.transforms.RegexRouter",
                    "transforms.addTopicPrefix.regex":"(.*)",
                    "transforms.addTopicPrefix.replacement":"mssql-04-$$1"
            }'
        #
        echo -e "\n--\n+> Creating Kafka Connect MySQL source"
        #
        curl -i -X PUT -H  "Content-Type:application/json" \
            http://localhost:8083/connectors/source-debezium-mysql-01/config \
            -d '{
                    "connector.class": "io.debezium.connector.mysql.MySqlConnector",
                    "database.hostname": "mysql",
                    "database.port": "3306",
                    "database.user": "debezium",
                    "database.password": "dbz",
                    "database.server.name": "asgard",
                    "database.history.kafka.bootstrap.servers": "$${file:/data/credentials.properties:CCLOUD_BROKER_HOST}:9092",
                    "database.history.kafka.topic": "dbz_dbhistory.mysql.asgard-04",
                    "database.history.consumer.security.protocol": "SASL_SSL",
                    "database.history.consumer.ssl.endpoint.identification.algorithm": "https",
                    "database.history.consumer.sasl.mechanism": "PLAIN",
                    "database.history.consumer.sasl.jaas.config": "org.apache.kafka.common.security.plain.PlainLoginModule required username=\"$${file:/data/credentials.properties:CCLOUD_API_KEY}\" password=\"$${file:/data/credentials.properties:CCLOUD_API_SECRET}\";",
                    "database.history.producer.security.protocol": "SASL_SSL",
                    "database.history.producer.ssl.endpoint.identification.algorithm": "https",
                    "database.history.producer.sasl.mechanism": "PLAIN",
                    "database.history.producer.sasl.jaas.config": "org.apache.kafka.common.security.plain.PlainLoginModule required username=\"$${file:/data/credentials.properties:CCLOUD_API_KEY}\" password=\"$${file:/data/credentials.properties:CCLOUD_API_SECRET}\";",
                    "table.whitelist":"demo.customers",
                    "transforms": "unwrap,addTopicPrefix",
                    "transforms.unwrap.type": "io.debezium.transforms.ExtractNewRecordState",
                    "transforms.addTopicPrefix.type":"org.apache.kafka.connect.transforms.RegexRouter",
                    "transforms.addTopicPrefix.regex":"(.*)",
                    "transforms.addTopicPrefix.replacement":"mysql-04-$$1"
            }'
        #
        echo -e "\n--\n+> Creating Kafka Connect Snowflake sink"
        curl -i -X PUT -H  "Content-Type:application/json" \
            http://localhost:8083/connectors/sink_snowflake_01/config \
            -d '{
                "connector.class":"com.snowflake.kafka.connector.SnowflakeSinkConnector",
                "tasks.max":1,
                "topics":"mssql-04-mssql.dbo.ORDERS,mysql-04-asgard.demo.customers,ORDERS_ENRICHED",
                "snowflake.url.name":"$${file:/data/credentials.properties:SNOWFLAKE_HOST}",
                "snowflake.user.name":"$${file:/data/credentials.properties:SNOWFLAKE_USER}",
                "snowflake.user.role":"SYSADMIN",
                "snowflake.private.key":"$${file:/data/credentials.properties:SNOWFLAKE_PRIVATE_KEY}",
                "snowflake.database.name":"DEMO_DB",
                "snowflake.schema.name":"PUBLIC",
                "key.converter":"org.apache.kafka.connect.storage.StringConverter",
                "value.converter":"com.snowflake.kafka.connector.records.SnowflakeAvroConverter",
                "value.converter.schema.registry.url":"https://$${file:/data/credentials.properties:CCLOUD_SCHEMA_REGISTRY_HOST}",
                "value.converter.basic.auth.credentials.source":"USER_INFO",
                "value.converter.basic.auth.user.info":"$${file:/data/credentials.properties:CCLOUD_SCHEMA_REGISTRY_API_KEY}:$${file:/data/credentials.properties:CCLOUD_SCHEMA_REGISTRY_API_SECRET}"
            }'
        #
        sleep infinity
    volumes: 
      - .env:/data/credentials.properties

  mysql:
    # *-----------------------------*
    # To connect to the DB: 
    #   docker exec -it mysql bash -c 'mysql -u $MYSQL_USER -p$MYSQL_PASSWORD demo'
    # *-----------------------------*
    image: mysql:8.0
    container_name: mysql
    ports:
      - 3306:3306
    environment:
     - MYSQL_ROOT_PASSWORD=Admin123
     - MYSQL_USER=connect_user
     - MYSQL_PASSWORD=asgard
    volumes:
     - ./data/mysql:/docker-entrypoint-initdb.d/

  mssql:
    # *-----------------------------*
    # To connect to the DB: 
    #   docker exec -it mssql bash -c '/opt/mssql-tools/bin/sqlcmd -l 30 -S localhost -U sa -P $SA_PASSWORD'
    # *-----------------------------*
    image: mcr.microsoft.com/mssql/server:2017-latest
    container_name: mssql
    ports: 
      - 1433:1433
    environment: 
      - SA_PASSWORD=Admin123
      - ACCEPT_EULA=Y
      - MSSQL_AGENT_ENABLED=true
    volumes:
     - ./data/mssql:/scripts/
    command:
      - /bin/bash
      - -c 
      - |
        # Launch MSSQL and send to background
        /opt/mssql/bin/sqlservr &
        # Wait for it to be available
        echo "Waiting for MS SQL to be available ⏳"
        /opt/mssql-tools/bin/sqlcmd -l 30 -S localhost -h-1 -V1 -U sa -P $$SA_PASSWORD -Q "SET NOCOUNT ON SELECT \"YAY WE ARE UP\" , @@servername"
        is_up=$$?
        while [ $$is_up -ne 0 ] ; do 
          echo -e $$(date) 
          /opt/mssql-tools/bin/sqlcmd -l 30 -S localhost -h-1 -V1 -U sa -P $$SA_PASSWORD -Q "SET NOCOUNT ON SELECT \"YAY WE ARE UP\" , @@servername"
          is_up=$$?
          sleep 5 
        done

        # Run every script in /scripts
        # TODO set a flag so that this is only done once on creation, 
        #      and not every time the container runs
        for foo in /scripts/*.sql
          do /opt/mssql-tools/bin/sqlcmd -U sa -P $$SA_PASSWORD -l 30 -e -i $$foo
        done
        # So that the container doesn't shut down, sleep this thread
        sleep infinity

  ksql-server:
    image: confluentinc/cp-ksql-server:5.4.0-beta1
    container_name: ksql-server
    ports: 
      - 8088:8088
    environment:
      KSQL_LISTENERS: http://0.0.0.0:8088
      KSQL_BOOTSTRAP_SERVERS: "${CCLOUD_BROKER_HOST}:9092"
      KSQL_KSQL_SCHEMA_REGISTRY_URL: "https://${CCLOUD_SCHEMA_REGISTRY_HOST}"
      KSQL_KSQL_SCHEMA_REGISTRY_BASIC_AUTH_CREDENTIALS_SOURCE: "USER_INFO"
      KSQL_KSQL_SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO: "${CCLOUD_SCHEMA_REGISTRY_API_KEY}:${CCLOUD_SCHEMA_REGISTRY_API_SECRET}"
      KSQL_LISTENERS: http://0.0.0.0:8088
      KSQL_KSQL_INTERNAL_TOPIC_REPLICAS: 3
      KSQL_KSQL_SERVICE_ID: rmoff_pipeline_04
      KSQL_CACHE_MAX_BYTES_BUFFERING: 0
      KSQL_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM: HTTPS
      KSQL_SECURITY_PROTOCOL: SASL_SSL
      KSQL_SASL_MECHANISM: PLAIN
      KSQL_SASL_JAAS_CONFIG: "org.apache.kafka.common.security.plain.PlainLoginModule required username=\"${CCLOUD_API_KEY}\" password=\"${CCLOUD_API_SECRET}\";"
      KSQL_KSQL_STREAMS_REPLICATION_FACTOR: 3
      KSQL_KSQL_SINK_REPLICAS: 3

  ksql-cli:
    image: confluentinc/cp-ksql-cli:5.4.0-beta1
    container_name: ksql-cli
    depends_on:
      - ksql-server
    entrypoint: /bin/sh
    tty: true
