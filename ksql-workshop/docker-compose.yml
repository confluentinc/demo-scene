---
version: '2'
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:5.2.1
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  kafka:
    image: confluentinc/cp-enterprise-kafka:5.2.1
    depends_on:
      - zookeeper
    ports:
    # Exposes 9092 for external connections to the broker
    # Use kafka:29092 for connections internal on the docker network
    # See https://rmoff.net/2018/08/02/kafka-listeners-explained/ for details
      - 9092:9092
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_METRIC_REPORTERS: io.confluent.metrics.reporter.ConfluentMetricsReporter
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 100
      CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: kafka:29092
      CONFLUENT_METRICS_REPORTER_ZOOKEEPER_CONNECT: zookeeper:2181
      CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 1
      CONFLUENT_METRICS_ENABLE: 'true'
      CONFLUENT_SUPPORT_CUSTOMER_ID: 'anonymous'

  schema-registry:
    image: confluentinc/cp-schema-registry:5.2.1
    depends_on:
      - zookeeper
      - kafka
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL: zookeeper:2181

  kafka-connect:
    image: confluentinc/cp-kafka-connect:5.2.1
    depends_on:
      - zookeeper
      - kafka
      - schema-registry
    ports:
      - 18083:18083
    environment:
      CONNECT_BOOTSTRAP_SERVERS: "kafka:29092"
      CONNECT_REST_PORT: 18083
      CONNECT_GROUP_ID: kafka-connect
      CONNECT_CONFIG_STORAGE_TOPIC: docker-kafka-connect-configs
      CONNECT_OFFSET_STORAGE_TOPIC: docker-kafka-connect-offsets
      CONNECT_STATUS_STORAGE_TOPIC: docker-kafka-connect-status
      CONNECT_KEY_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: 'http://schema-registry:8081'
      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: 'http://schema-registry:8081'
      CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_REST_ADVERTISED_HOST_NAME: "kafka-connect"
      CONNECT_LOG4J_ROOT_LOGLEVEL: "INFO"
      CONNECT_LOG4J_LOGGERS: "org.apache.kafka.connect.runtime.rest=WARN,org.reflections=ERROR"
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_PLUGIN_PATH: '/usr/share/java'
      # Interceptor config
      CONNECT_PRODUCER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor"
      CONNECT_CONSUMER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor"
      CLASSPATH: /usr/share/java/monitoring-interceptors/monitoring-interceptors-5.1.1.jar

  ksql-server:
    image: confluentinc/cp-ksql-server:5.2.1
    ports: 
      - 8088:8088
    depends_on:
      - kafka
      - schema-registry
    environment:
      KSQL_CUB_KAFKA_TIMEOUT: 120
      KSQL_BOOTSTRAP_SERVERS: kafka:29092
      KSQL_LISTENERS: http://0.0.0.0:8088
      KSQL_KSQL_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      KSQL_KSQL_COMMIT_INTERVAL_MS: 2000
      KSQL_KSQL_CACHE_MAX_BYTES_BUFFERING: 10000000
      KSQL_KSQL_SERVICE_ID: confluent_rmoff_01
      # Producer Confluent Monitoring Interceptors for Control Center streams monitoring
      KSQL_PRODUCER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor"
      KSQL_CONSUMER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor"

  ksql-cli:
    image: confluentinc/cp-ksql-cli:5.2.1
    depends_on:
      - ksql-server
    entrypoint: /bin/sh
    tty: true

  kafkacat:
    image: confluentinc/cp-kafkacat:latest
    depends_on:
      - kafka
    entrypoint: sleep infinity

  # Runs the Kafka KSQL data generator for ratings
  datagen-ratings:
    image: confluentinc/ksql-examples:5.2.1
    depends_on:
      - kafka
      - schema-registry
    command: "bash -c 'echo Waiting for Kafka to be ready... && \
                       cub kafka-ready -b kafka:29092 1 300 && \
                       echo Waiting for Confluent Schema Registry to be ready... && \
                       cub sr-ready schema-registry 8081 300 && \
                       echo Waiting a few seconds for topic creation to finish... && \
                       sleep 20 && \
                       ksql-datagen \
                          quickstart=ratings \
                          format=avro \
                          topic=ratings \
                          maxInterval=500 \
                          bootstrap-server=kafka:29092 \
                          schemaRegistryUrl=http://schema-registry:8081 \
                          propertiesFile=/etc/ksql/datagen.properties'"


  # control-center:
  #   image: confluentinc/cp-enterprise-control-center:5.2.1
  #   depends_on:
  #     - zookeeper
  #     - kafka
  #     - schema-registry
  #     - kafka-connect
  #     - ksql-server
  #   ports:
  #     - "9021:9021"
  #   environment:
  #     CONTROL_CENTER_BOOTSTRAP_SERVERS: 'kafka:29092'
  #     CONTROL_CENTER_ZOOKEEPER_CONNECT: 'zookeeper:2181'
  #     CONTROL_CENTER_CONNECT_CLUSTER: 'kafka-connect:8083'
  #     CONTROL_CENTER_KSQL_URL: "http://ksql-server:8088"
  #     # The advertised URL needs to be the URL on which the *browser*
  #     #  can access the KSQL server (e.g. http://localhost:8088/info)
  #     CONTROL_CENTER_KSQL_ADVERTISED_URL: "http://localhost:8088"
  #     CONTROL_CENTER_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
  #     CONTROL_CENTER_REPLICATION_FACTOR: 1
  #     CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS: 1
  #     CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS: 1
  #     CONFLUENT_METRICS_TOPIC_REPLICATION: 1
  #     PORT: 9021
  #   command:
  #     - bash
  #     - -c 
  #     - |
  #       echo "Waiting two minutes for Kafka brokers to start and 
  #              necessary topics to be available"
  #       sleep 120  
  #       /etc/confluent/docker/run

# Other systems
  mysql:
    # *-----------------------------*
    # To connect to the DB: 
    #   docker-compose exec mysql bash -c 'mysql -u root -p$MYSQL_ROOT_PASSWORD'
    # *-----------------------------*
    image: debezium/example-mysql:0.9
    ports:
      - 3306:3306
    environment:
     - MYSQL_ROOT_PASSWORD=debezium
     - MYSQL_USER=mysqluser
     - MYSQL_PASSWORD=mysqlpw
    volumes:
     - ${PWD}/data/customers.sql:/docker-entrypoint-initdb.d/z99_dump.sql

  connect-debezium:
    image: debezium/connect:0.9.3.Final
    depends_on:
     - kafka
     - mysql
     - schema-registry
    ports:
     - 8083:8083
    environment:
      BOOTSTRAP_SERVERS: kafka:29092
      GROUP_ID: connect-debezium
      CONFIG_STORAGE_TOPIC: docker-connect-debezium-configs
      OFFSET_STORAGE_TOPIC: docker-connect-debezium-offsets
      STATUS_STORAGE_TOPIC: docker-connect-debezium-status
      KEY_CONVERTER: io.confluent.connect.avro.AvroConverter
      VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
    volumes:
     - ${PWD}/scripts:/scripts
     
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:6.3.0
    ports:
      - 9200:9200
    environment:
      xpack.security.enabled: "false"
      ES_JAVA_OPTS: "-Xms1g -Xmx1g"
    volumes:
     - ${PWD}/scripts:/scripts

  kibana:
    image: docker.elastic.co/kibana/kibana:6.3.0
    depends_on:
      - elasticsearch
    ports:
      - 5601:5601
    environment:
      xpack.security.enabled: "false"
      discovery.type: "single-node"
