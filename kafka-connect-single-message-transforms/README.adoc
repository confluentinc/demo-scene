= ğŸ… ğŸ„ Twelve Days of SMT ğŸ„ ğŸ… 

Kafka Connect's Single Message Transform functionality is really useful for building data pipelines that modify the data passing through, without needing - use stream processing like Kafka Streams or ksqlDB. 

* link:day1.adoc[Day 1] - `InsertField` - add message timestamp as a field - a sink
* link:day2.adoc[Day 2] - `ValueToKey` and `ExtractField` - set the message key - a field from the value
* link:day3.adoc[Day 3] - `Flatten` - turn a nested structure into a flat one
* link:day4.adoc[Day 4] - `RegexRouter` - change the topic name based on a pattern match and replacement
* link:day5.adoc[Day 5] - `MaskField` - mask the value of fields with a fixed replacement string
* link:day6.adoc[Day 6] - `InsertField` - same SMT as link:day1.adoc[Day 1], this time showing adding to the payload the topic name, Kafka message partition and offset, as well as hardcoded values 
* link:day7.adoc[Day 7] - `TimestampRouter` - change the topic name based on the timestamp of the Kafka message
* Day 8 - ğŸ“º Stay tuned
* Day 9 - ğŸ“º Stay tuned
* Day 10 - ğŸ“º Stay tuned
* Day 11 - ğŸ“º Stay tuned
* Day 12 - ğŸ“º Stay tuned
